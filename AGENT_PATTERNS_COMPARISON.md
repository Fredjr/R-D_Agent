# üé® AGENT ARCHITECTURE PATTERNS - APPLICABILITY TO R&D AGENT

**Date:** November 22, 2025

---

## üìä THREE PATTERNS FROM YOUR REFERENCE

### Pattern 1: Sequential + MCP Servers + Tools

**Description:** Agents work sequentially, each with its own model and tools.

**Example from Image:**
```
Webhook ‚Üí Agent1 (OpenAI + Contacts) ‚Üí Agent2 (OpenAI + Gmail) ‚Üí Response
```

**Applicability to R&D Agent:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê **HIGHLY APPLICABLE**

**How to Apply:**
```
User Request
    ‚Üì
Agent 1: Data Gatherer
    - Model: GPT-4o-mini
    - Tools: PostgreSQL queries
    - Output: Structured project data
    ‚Üì
Agent 2: Insight Analyzer
    - Model: GPT-4o-mini
    - Tools: Statistical analysis
    - Input: Data from Agent 1
    - Output: Progress, gaps, trends
    ‚Üì
Agent 3: Recommendation Generator
    - Model: GPT-4o-mini
    - Tools: Research best practices DB
    - Input: Insights from Agent 2
    - Output: Actionable recommendations
    ‚Üì
Response to User
```

**Benefits:**
- ‚úÖ Clear separation of concerns
- ‚úÖ Each agent has specific expertise
- ‚úÖ Easy to debug (know which agent failed)
- ‚úÖ Can use different models per agent (cost optimization)

**Implementation Priority:** üî¥ HIGH (Phase 2)

---

### Pattern 2: Agents Hierarchy + Shared Tools + Parallel

**Description:** Supervisor agent routes to specialized agents that run in parallel and share tools.

**Example from Image:**
```
Webhook ‚Üí Supervisor (Switch) ‚Üí [Agent2 || Agent3 || Agent4] ‚Üí Shared Tools (Gmail, Twilio) ‚Üí Response
```

**Applicability to R&D Agent:** ‚≠ê‚≠ê‚≠ê‚≠ê **VERY APPLICABLE**

**How to Apply:**
```
User Request
    ‚Üì
Supervisor Agent (NEW)
    - Analyzes request complexity
    - Decides which agents to invoke
    - Routes based on project state
    ‚Üì
    ‚îú‚îÄ‚Üí Progress Agent (parallel)
    ‚îÇ   ‚îî‚îÄ‚Üí Shared Tool: Vector Search
    ‚îÇ
    ‚îú‚îÄ‚Üí Gap Agent (parallel)
    ‚îÇ   ‚îî‚îÄ‚Üí Shared Tool: Vector Search
    ‚îÇ
    ‚îî‚îÄ‚Üí Trend Agent (parallel)
        ‚îî‚îÄ‚Üí Shared Tool: Vector Search
    ‚Üì
Supervisor merges results
    ‚Üì
Response to User
```

**Benefits:**
- ‚úÖ Parallel execution (3x faster)
- ‚úÖ Shared vector search (cost efficient)
- ‚úÖ Dynamic routing (only invoke needed agents)
- ‚úÖ Scalable (easy to add new agents)

**Implementation Priority:** üü° MEDIUM (Phase 3)

---

### Pattern 3: Agents Hierarchy + Loop + Parallel + Shared RAG

**Description:** Agents work in a loop with parallel execution and shared RAG, merging results iteratively.

**Example from Image:**
```
Webhook ‚Üí Agent7 (Memory + Calculator) ‚Üí Switch ‚Üí [Agent8 || Agent9] ‚Üí Merge ‚Üí Loop back or Response
                                                    ‚Üì
                                            Shared Vector Store
```

**Applicability to R&D Agent:** ‚≠ê‚≠ê‚≠ê **MODERATELY APPLICABLE**

**How to Apply:**
```
User Request
    ‚Üì
Coordinator Agent (NEW)
    - Working Memory: Track iteration state
    - Tools: Confidence calculator
    ‚Üì
Switch: Is analysis complete?
    ‚îú‚îÄ‚Üí NO: Continue loop
    ‚îÇ   ‚Üì
    ‚îÇ   ‚îú‚îÄ‚Üí Literature Agent (parallel)
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚Üí Shared RAG: Vector Store
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îî‚îÄ‚Üí Experiment Agent (parallel)
    ‚îÇ       ‚îî‚îÄ‚Üí Shared RAG: Vector Store
    ‚îÇ   ‚Üì
    ‚îÇ   Merge results
    ‚îÇ   ‚Üì
    ‚îÇ   Update Working Memory
    ‚îÇ   ‚Üì
    ‚îÇ   Loop back to Switch
    ‚îÇ
    ‚îî‚îÄ‚Üí YES: Generate final insights
        ‚Üì
        Response to User
```

**Use Case:** Iterative hypothesis refinement

**Example Scenario:**
1. **Iteration 1:** Analyze initial hypothesis confidence (50%)
2. **Iteration 2:** Find supporting papers ‚Üí confidence increases (70%)
3. **Iteration 3:** Find experiment results ‚Üí confidence increases (85%)
4. **Stop:** Confidence threshold reached, return insights

**Benefits:**
- ‚úÖ Iterative refinement
- ‚úÖ Adaptive depth (stop when confident)
- ‚úÖ Shared RAG reduces redundant searches
- ‚úÖ Working memory tracks progress

**Challenges:**
- ‚ö†Ô∏è More complex to implement
- ‚ö†Ô∏è Risk of infinite loops
- ‚ö†Ô∏è Higher latency (multiple iterations)

**Implementation Priority:** üü¢ LOW (Future enhancement)

---

## üéØ RECOMMENDED PATTERN FOR R&D AGENT

### **Hybrid: Sequential + Parallel + Shared RAG**

**Why this combination?**
1. **Sequential for data gathering** (must happen first)
2. **Parallel for analysis** (insights, gaps, trends can run simultaneously)
3. **Shared RAG** (all agents use same vector store)

**Architecture:**
```
User Request
    ‚Üì
[SEQUENTIAL] Data Gathering Agent
    - Fetch project data from PostgreSQL
    - Build context
    ‚Üì
[PARALLEL] Analysis Agents
    ‚îú‚îÄ‚Üí Progress Agent
    ‚îú‚îÄ‚Üí Connection Agent
    ‚îú‚îÄ‚Üí Gap Agent
    ‚îî‚îÄ‚Üí Trend Agent
    ‚Üì
    All share: Vector Store (semantic search)
    ‚Üì
[SEQUENTIAL] Recommendation Agent
    - Takes all analysis results
    - Generates actionable next steps
    ‚Üì
Response to User
```

**Performance Gains:**
- Current: 10 seconds (all sequential)
- With parallel: 4 seconds (4 agents run simultaneously)
- With vector search: 3 seconds (less data to process)
- **Total improvement: 70% faster**

---

## üìã IMPLEMENTATION GUIDE

### Step 1: Add Orchestration Layer (Week 1)

**File:** `backend/app/services/orchestrator_service.py`

```python
import asyncio
from typing import Dict
from sqlalchemy.orm import Session

class OrchestratorService:
    """Coordinates multiple AI agents"""
    
    def __init__(self):
        self.insights_service = InsightsService()
        self.summary_service = LivingSummaryService()
    
    async def generate_project_analysis(
        self, 
        project_id: str, 
        db: Session
    ) -> Dict:
        """Run insights and summary in parallel"""
        
        # Phase 1: Sequential data gathering (must happen first)
        project_data = await self._gather_project_data(project_id, db)
        
        # Phase 2: Parallel analysis
        insights_task = asyncio.create_task(
            self.insights_service.generate_insights_from_data(project_data)
        )
        summary_task = asyncio.create_task(
            self.summary_service.generate_summary_from_data(project_data)
        )
        
        insights, summary = await asyncio.gather(
            insights_task, 
            summary_task,
            return_exceptions=True  # Don't fail if one agent fails
        )
        
        # Phase 3: Merge results
        return {
            'insights': insights if not isinstance(insights, Exception) else None,
            'summary': summary if not isinstance(summary, Exception) else None,
            'generated_at': datetime.now(timezone.utc),
            'errors': self._collect_errors([insights, summary])
        }
```

**Benefits:**
- ‚ö° 2x faster (parallel execution)
- üõ°Ô∏è Fault tolerant (one agent failure doesn't break everything)
- üîÑ Easy to add more agents

---

### Step 2: Add Vector Memory (Week 2-3)

**File:** `backend/database.py`

```python
from pgvector.sqlalchemy import Vector

class EntityEmbedding(Base):
    """Vector embeddings for semantic search"""
    __tablename__ = "entity_embeddings"
    
    embedding_id = Column(String, primary_key=True)
    entity_type = Column(String)  # 'question', 'hypothesis', 'paper', etc.
    entity_id = Column(String)
    project_id = Column(String, ForeignKey("projects.project_id"))
    embedding = Column(Vector(1536))  # OpenAI ada-002
    text_content = Column(Text)
    metadata = Column(JSON)
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    
    __table_args__ = (
        Index('idx_entity_embeddings_project', 'project_id'),
        Index('idx_entity_embeddings_type', 'entity_type'),
    )
```

**File:** `backend/app/services/vector_service.py`

```python
from openai import AsyncOpenAI
from sqlalchemy import text

client = AsyncOpenAI()

class VectorService:
    """Semantic search using vector embeddings"""
    
    async def embed_entity(
        self, 
        entity_type: str, 
        entity_id: str, 
        text: str,
        db: Session
    ):
        """Create embedding for an entity"""
        response = await client.embeddings.create(
            model="text-embedding-ada-002",
            input=text
        )
        embedding = response.data[0].embedding
        
        # Store in database
        entity_embedding = EntityEmbedding(
            embedding_id=str(uuid.uuid4()),
            entity_type=entity_type,
            entity_id=entity_id,
            embedding=embedding,
            text_content=text
        )
        db.add(entity_embedding)
        db.commit()
    
    async def semantic_search(
        self,
        query: str,
        entity_types: List[str],
        project_id: str,
        top_k: int,
        db: Session
    ) -> List[Dict]:
        """Search for similar entities"""
        # Embed query
        response = await client.embeddings.create(
            model="text-embedding-ada-002",
            input=query
        )
        query_embedding = response.data[0].embedding
        
        # Vector similarity search using pgvector
        sql = text("""
            SELECT 
                entity_type,
                entity_id,
                text_content,
                1 - (embedding <=> :query_embedding) as similarity
            FROM entity_embeddings
            WHERE project_id = :project_id
              AND entity_type = ANY(:entity_types)
            ORDER BY embedding <=> :query_embedding
            LIMIT :top_k
        """)
        
        results = db.execute(sql, {
            'query_embedding': query_embedding,
            'project_id': project_id,
            'entity_types': entity_types,
            'top_k': top_k
        }).fetchall()
        
        return [
            {
                'entity_type': r.entity_type,
                'entity_id': r.entity_id,
                'text': r.text_content,
                'similarity': r.similarity
            }
            for r in results
        ]
```

**Benefits:**
- üéØ Retrieve only relevant entities
- üí∞ 60% reduction in token usage
- ‚ö° Faster generation (less context)

---

### Step 3: Add Evaluation Service (Week 4)

**File:** `backend/app/services/evaluation_service.py`

```python
class EvaluationService:
    """Evaluate AI agent outputs"""
    
    async def evaluate_insights(
        self, 
        insights: Dict, 
        project_data: Dict
    ) -> Dict:
        """Comprehensive evaluation of insights"""
        
        return {
            'completeness_score': self._check_completeness(insights),
            'relevance_score': await self._check_relevance(insights, project_data),
            'actionability_score': self._check_actionability(insights),
            'hallucination_score': await self._detect_hallucinations(insights, project_data),
            'overall_score': self._calculate_overall_score(insights)
        }
    
    def _check_completeness(self, insights: Dict) -> float:
        """Check if all required fields are present"""
        required_fields = [
            'progress_insights',
            'connection_insights',
            'gap_insights',
            'trend_insights',
            'recommendations'
        ]
        
        present = sum(
            1 for field in required_fields 
            if insights.get(field) and len(insights[field]) > 0
        )
        
        return present / len(required_fields)
    
    def _check_actionability(self, insights: Dict) -> float:
        """Check if recommendations are actionable"""
        recs = insights.get('recommendations', [])
        if not recs:
            return 0.0
        
        actionable = sum(
            1 for rec in recs
            if rec.get('action') and rec.get('estimated_effort')
        )
        
        return actionable / len(recs)
    
    async def _detect_hallucinations(
        self, 
        insights: Dict, 
        project_data: Dict
    ) -> float:
        """Use AI to detect hallucinations"""
        
        # Extract all entity mentions from insights
        mentioned_entities = self._extract_entity_mentions(insights)
        
        # Check if they exist in project data
        actual_entities = self._extract_actual_entities(project_data)
        
        # Calculate hallucination rate
        hallucinated = [
            e for e in mentioned_entities 
            if e not in actual_entities
        ]
        
        if not mentioned_entities:
            return 0.0
        
        return len(hallucinated) / len(mentioned_entities)
```

**Benefits:**
- üõ°Ô∏è Catch bad outputs before they reach users
- ÔøΩÔøΩ Track quality metrics over time
- üîÑ Identify areas for improvement

---

## üéØ EXPECTED OUTCOMES

### Performance Improvements

| Metric | Current | After Phase 1 | After Phase 2 | After Phase 3 |
|--------|---------|---------------|---------------|---------------|
| **Response Time** | 10s | 5s | 3s | 2s |
| **Token Usage** | 100% | 100% | 60% | 40% |
| **Quality Score** | N/A | 70% | 80% | 90% |
| **Parallel Agents** | 0 | 2 | 4 | 6 |
| **Cost per Request** | $0.10 | $0.10 | $0.06 | $0.04 |

### Quality Improvements

| Aspect | Current | After Implementation |
|--------|---------|---------------------|
| **Relevance** | Medium | High (vector search) |
| **Completeness** | Unknown | Measured & tracked |
| **Hallucinations** | Unknown | Detected & prevented |
| **Actionability** | Unknown | Scored & optimized |

---

## üöÄ QUICK START GUIDE

### This Week (Immediate Impact)

1. **Create Orchestrator** (2 hours)
   - File: `backend/app/services/orchestrator_service.py`
   - Benefit: 2x faster responses

2. **Add Parallel Execution** (1 hour)
   - Use `asyncio.gather()` for insights + summary
   - Benefit: Immediate performance gain

3. **Add Basic Evaluation** (2 hours)
   - Check completeness and actionability
   - Benefit: Quality visibility

### Next Week (Foundation)

4. **Install pgvector** (30 minutes)
   ```sql
   CREATE EXTENSION vector;
   ```

5. **Create EntityEmbedding Model** (1 hour)
   - Add to `database.py`
   - Run migration

6. **Implement VectorService** (4 hours)
   - Embedding creation
   - Semantic search

### Month 2 (Advanced)

7. **Split into Specialized Agents** (1 week)
   - Progress Agent
   - Gap Agent
   - Trend Agent
   - Recommendation Agent

8. **Add Supervisor Pattern** (1 week)
   - Dynamic routing
   - Agent coordination

9. **Comprehensive Evaluation** (1 week)
   - Hallucination detection
   - Quality dashboard

---

## üìä CONCLUSION

**Best Pattern for R&D Agent:** Sequential + Parallel + Shared RAG

**Why?**
- ‚úÖ Balances complexity and performance
- ‚úÖ Easy to implement incrementally
- ‚úÖ Significant performance gains (70% faster)
- ‚úÖ Cost reduction (60% fewer tokens)
- ‚úÖ Quality improvements (measurable)

**Start with:** Orchestration layer for immediate 2x speedup!
